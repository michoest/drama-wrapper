{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(f'{os.getcwd()}/../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "import gymnasium as gym\n",
    "from decimal import Decimal\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.random import Generator\n",
    "from gymnasium.spaces import Box, Discrete\n",
    "from pettingzoo import AECEnv\n",
    "import matplotlib\n",
    "\n",
    "from src.wrapper import RestrictionWrapper\n",
    "from src.restrictors import Restrictor, RestrictorActionSpace, IntervalUnionActionSpace\n",
    "from src.restrictions import BucketSpace, IntervalUnionRestriction\n",
    "\n",
    "from examples.envs.nfg import NFGEnvironment\n",
    "from examples.utils import play"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the Cournot Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum_price = 120\n",
    "cost = 12\n",
    "\n",
    "observation_spaces = {'player_0': Box(0, maximum_price), 'player_1': Box(0, maximum_price)}\n",
    "action_spaces = {'player_0': Box(0, maximum_price), 'player_1': Box(0, maximum_price)}\n",
    "utilities = {\n",
    "    'player_0': (lambda actions: -actions['player_0'] ** 2 - actions['player_0'] * actions['player_1'] + (maximum_price - cost) * actions['player_0']), \n",
    "    'player_1': (lambda actions: -actions['player_1'] ** 2 - actions['player_0'] * actions['player_1'] + (maximum_price - cost) * actions['player_1'])}\n",
    "\n",
    "env = NFGEnvironment(observation_spaces, action_spaces, utilities, number_of_steps=100, render_mode='human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Players always choose the best response to the opponent's action\n",
    "\n",
    "def unrestricted_agent_policy(observation):\n",
    "    opponent_action = observation[0]\n",
    "    if opponent_action is None:\n",
    "        return np.random.randint(0, 121)\n",
    "    else:\n",
    "        return np.clip(54 - opponent_action / 2, 0, 120)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test: Play without restrictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policies = {'player_0': unrestricted_agent_policy, 'player_1': unrestricted_agent_policy}\n",
    "play(env, policies, max_iter=20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-learning restrictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Players always choose the best response to the opponent's action, given the restriction\n",
    "class CournotAgent:\n",
    "    def __init__(self, _lambda: float) -> None:\n",
    "        self._lambda = _lambda\n",
    "\n",
    "    def act(self, observation):\n",
    "        observation, restriction = observation['observation'], observation['restriction']\n",
    "        opponent_action = observation[0]\n",
    "        if opponent_action is None:\n",
    "            return np.random.uniform(0, maximum_price)\n",
    "        else:\n",
    "            unrestricted_best_response = (self._lambda - opponent_action) / 2\n",
    "            if restriction.contains(unrestricted_best_response):\n",
    "                return unrestricted_best_response\n",
    "            else:\n",
    "                [ll, lu], _ = restriction.last_interval_before_or_within(unrestricted_best_response)\n",
    "                [ul, uu], _ = restriction.first_interval_after_or_within(unrestricted_best_response)\n",
    "\n",
    "                if ll is None:\n",
    "                    return float(ul)\n",
    "                elif ul is None:\n",
    "                    return float(lu)\n",
    "                else:\n",
    "                    ll, lu, ul, uu = float(ll), float(lu), float(ul), float(uu)\n",
    "\n",
    "                    return lu if (unrestricted_best_response - lu) < 2 * (ul - unrestricted_best_response) else ul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CournotRestrictor(Restrictor):\n",
    "    def __init__(self, observation_space, action_space) -> None:\n",
    "        super().__init__(observation_space, action_space)\n",
    "\n",
    "        self.previous_observation = None\n",
    "        self.restriction = IntervalUnionRestriction(self.action_space.base_space)\n",
    "        self.has_restricted = False\n",
    "\n",
    "    def preprocess_observation(self, env: AECEnv):\n",
    "        return np.array(list(env.state().values()), dtype=float)\n",
    "    \n",
    "    def act(self, observation: gym.Space) -> RestrictorActionSpace:\n",
    "        if not np.isnan(observation).any():\n",
    "            if not self.has_restricted and self.previous_observation is not None:\n",
    "                if np.allclose(observation, self.previous_observation, atol=0.001):\n",
    "                    estimated_lambda = 3 / 2 * observation.sum()\n",
    "                    self.restriction.remove(estimated_lambda / 4, estimated_lambda / 2)\n",
    "                    self.has_restricted = True\n",
    "\n",
    "            self.previous_observation = observation\n",
    "\n",
    "        return self.restriction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = [CournotAgent(maximum_price - cost), CournotAgent(maximum_price - cost)]\n",
    "restrictor = CournotRestrictor(Box(0, maximum_price, shape=(2, )), IntervalUnionActionSpace(Box(0, maximum_price)))\n",
    "wrapper = RestrictionWrapper(env, restrictor)\n",
    "\n",
    "policies = {'player_0': agents[0].act, 'player_1': agents[1].act, 'restrictor_0': restrictor.act}\n",
    "trajectory = play(wrapper, policies, max_iter=100, render_mode=None, record_trajectory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory.groupby('agent')['reward'].plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
