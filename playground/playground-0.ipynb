{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(f'{os.getcwd()}/../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Optional, Any, Set, Sequence\n",
    "from abc import ABC\n",
    "\n",
    "import functools\n",
    "import random\n",
    "\n",
    "import gymnasium\n",
    "import numpy as np\n",
    "from numpy.random import Generator\n",
    "import gymnasium.spaces\n",
    "from gymnasium.spaces import Discrete, Space, Dict\n",
    "\n",
    "from pettingzoo import AECEnv\n",
    "from pettingzoo.utils import agent_selector, wrappers\n",
    "from pettingzoo.test import api_test\n",
    "from pettingzoo.utils.env import AECIterable, AgentID, ActionType, ObsType\n",
    "\n",
    "from src.wrapper import RestrictionWrapper\n",
    "from src.multi_restriction_wrapper import MultiRestrictionWrapper\n",
    "from examples.envs.rps import RPSEnvironment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RestrictorActionSpace(gymnasium.Space):\n",
    "    def __init__(self, base_space: gymnasium.Space, seed: int | Generator | None = None):\n",
    "        super().__init__(None, None, seed)\n",
    "        self.base_space = base_space\n",
    "\n",
    "    def contains(self, x: Restriction) -> bool:\n",
    "        return x.base_space == self.base_space\n",
    "    \n",
    "    def sample(self, mask: Any | None = None) -> Any:\n",
    "        return self.base_space\n",
    "\n",
    "    def is_compatible_with(self, action_space):\n",
    "        return self.base_space == action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Restriction(ABC, gymnasium.Space):\n",
    "    def __init__(self, base_space: gymnasium.Space, *, seed: int | np.random.Generator | None = None):\n",
    "        super().__init__(base_space.shape, base_space.dtype, seed)\n",
    "        self.base_space = base_space\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f'{self.__class__.__name__}'\n",
    "\n",
    "class DiscreteRestriction(Restriction):\n",
    "    def __init__(self, base_space: gymnasium.spaces.Discrete, *, seed: int | np.random.Generator | None = None):\n",
    "        super().__init__(base_space, seed=seed)\n",
    "\n",
    "class ContinuousRestriction(Restriction):\n",
    "    def __init__(self, base_space: gymnasium.spaces.Box, *, seed: int | np.random.Generator | None = None):\n",
    "        super().__init__(base_space, seed=seed)\n",
    "\n",
    "class DiscreteSetRestriction(DiscreteRestriction):\n",
    "    def __init__(self, base_space: gymnasium.spaces.Discrete, *, allowed_actions: Optional[Set[int]] = None, seed: int | np.random.Generator | None = None):\n",
    "        super().__init__(base_space, seed=seed)\n",
    "        \n",
    "        self.allowed_actions = allowed_actions if allowed_actions is not None else set(range(base_space.start, base_space.start + base_space.n))\n",
    "\n",
    "    @property\n",
    "    def is_np_flattenable(self) -> bool:\n",
    "        return True\n",
    "    \n",
    "    def sample(self) -> int:\n",
    "        return random.choice(tuple(self.allowed_actions))\n",
    "\n",
    "    def contains(self, x: int) -> bool:\n",
    "        return x in self.allowed_actions\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return f'{self.__class__.__name__}({self.allowed_actions})'\n",
    "\n",
    "class DiscreteVectorRestriction(DiscreteRestriction):\n",
    "    def __init__(self, base_space: gymnasium.spaces.Discrete, *, allowed_actions: Optional[np.ndarray[bool]] = None, seed: int | np.random.Generator | None = None):\n",
    "        super().__init__(base_space, seed=seed)\n",
    "        \n",
    "        self.allowed_actions = allowed_actions if allowed_actions is not None else set(range(base_space.start, base_space.start + base_space.n))\n",
    "\n",
    "    @property\n",
    "    def is_np_flattenable(self) -> bool:\n",
    "        return True\n",
    "    \n",
    "    def sample(self) -> int:\n",
    "        return self.start + random.choice(tuple(index for index, value in enumerate(self.allowed_actions) if value))\n",
    "\n",
    "    def contains(self, x: int) -> bool:\n",
    "        return self.allowed_actions[x - self.start]\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return f'{self.__class__.__name__}({self.allowed_actions})'\n",
    "\n",
    "class IntervalUnionRestriction(ContinuousRestriction):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Restrictor:\n",
    "    default_restriction_classes = {\n",
    "        gymnasium.spaces.Discrete: DiscreteSetRestriction,\n",
    "        gymnasium.spaces.Box: IntervalUnionRestriction\n",
    "    }\n",
    "\n",
    "    def __init__(self, env, restriction_classes=None) -> None:\n",
    "        self.action_spaces = {agent: env.action_space(agent) for agent in env.possible_agents}\n",
    "        self.restriction_classes = restriction_classes or self.default_restriction_classes\n",
    "\n",
    "class RPSRestrictor(Restrictor):\n",
    "    def __init__(self, env, restriction_classes=None) -> None:\n",
    "        super().__init__(env, restriction_classes=restriction_classes)\n",
    "\n",
    "        self.observation_space = Discrete(1)\n",
    "        self.action_space = RestrictorActionSpace(Discrete(3))\n",
    "\n",
    "    def preprocess_observation(self, env):\n",
    "        # This functions 'flattens' the environment into a valid space while preserving all information that the restrictor needs\n",
    "        return {'agent': env.agent_selection, 'last_action': int(env.observe(env.possible_agents[1 - env.agent_name_mapping[env.agent_selection]]))}\n",
    "\n",
    "    def act(self, observation):\n",
    "        # Structure of observation is defined by self.preprocess_observation\n",
    "        agent, last_action = observation['agent'], observation['last_action']\n",
    "\n",
    "        return DiscreteSetRestriction(Discrete(3), allowed_actions={0, 1, 2} - {last_action})\n",
    "    \n",
    "class DummyRPSRestrictor(Restrictor):\n",
    "    def __init__(self) -> None:\n",
    "        # TODO: Create concept for observation space handling\n",
    "        self.observation_space = Discrete(1)\n",
    "        self.action_space = RestrictorActionSpace(Discrete(3))\n",
    "\n",
    "    def act(self, observation):\n",
    "        return DiscreteSetRestriction(Discrete(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restriction_aware_random_policy(observation):\n",
    "    observation, restriction = observation['observation'], observation['restriction']\n",
    "    return restriction.sample()\n",
    "\n",
    "def create_policies(env, restrictors):\n",
    "    return {**{agent: restriction_aware_random_policy for agent in env.possible_agents}, **{id: restrictor.act for id, restrictor in restrictors.items()}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play(env, policies, *, max_iter=1_000, verbose=False):\n",
    "    env.reset()\n",
    "    env.render()\n",
    "\n",
    "    for agent in env.agent_iter():\n",
    "        observation, reward, termination, truncation, info = env.last()\n",
    "        if verbose:\n",
    "            print(f'{agent=}, {observation=}, {reward=}, {termination=}, {truncation=}, {info=}')\n",
    "\n",
    "        action = policies[agent](observation) if not termination and not truncation else None\n",
    "        if verbose:\n",
    "            print(f'{action=}')\n",
    "\n",
    "        env.step(action)\n",
    "    \n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "The action space of restrictor_1 and player_0 are not compatible!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[145], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m env \u001b[39m=\u001b[39m RPSEnvironment(render_mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhuman\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m restrictors \u001b[39m=\u001b[39m {\n\u001b[1;32m      3\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mrestrictor_0\u001b[39m\u001b[39m'\u001b[39m: RPSRestrictor(env), \u001b[39m# Restrictor blocks each player's last action\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mrestrictor_1\u001b[39m\u001b[39m'\u001b[39m: DummyRPSRestrictor()\n\u001b[1;32m      5\u001b[0m }\n\u001b[0;32m----> 7\u001b[0m wrapper \u001b[39m=\u001b[39m MultiRestrictionWrapper(env, restrictors, \n\u001b[1;32m      8\u001b[0m                                   {\u001b[39m'\u001b[39;49m\u001b[39mplayer_0\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39mrestrictor_1\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mplayer_1\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39mrestrictor_1\u001b[39;49m\u001b[39m'\u001b[39;49m}, \n\u001b[1;32m      9\u001b[0m                                   preprocess_restrictor_observation_fns\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mrestrictor_0\u001b[39;49m\u001b[39m'\u001b[39;49m: restrictors[\u001b[39m'\u001b[39;49m\u001b[39mrestrictor_0\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mpreprocess_observation})\n\u001b[1;32m     11\u001b[0m play(wrapper, create_policies(env, restrictors))\n",
      "File \u001b[0;32m~/Documents/Professional/Promotion/InES/Conferences and Journals/13 HICSS 2024/hicss-2024/playground/../src/multi_restriction_wrapper.py:56\u001b[0m, in \u001b[0;36mMultiRestrictionWrapper.__init__\u001b[0;34m(self, env, restrictors, agent_restrictor_mapping, restrictor_reward_fns, preprocess_restrictor_observation_fns, restriction_key, observation_key)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[39m# Check if restrictor action spaces match agent action spaces\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[39mfor\u001b[39;00m agent \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mpossible_agents:\n\u001b[0;32m---> 56\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrestrictors[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39magent_restrictor_mapping[agent]]\u001b[39m.\u001b[39maction_space\u001b[39m.\u001b[39mis_compatible_with(env\u001b[39m.\u001b[39maction_space(agent)), \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mThe action space of \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39magent_restrictor_mapping[agent]\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00magent\u001b[39m}\u001b[39;00m\u001b[39m are not compatible!\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: The action space of restrictor_1 and player_0 are not compatible!"
     ]
    }
   ],
   "source": [
    "env = RPSEnvironment(render_mode='human')\n",
    "restrictors = {\n",
    "    'restrictor_0': RPSRestrictor(env), # Restrictor blocks each player's last action\n",
    "    'restrictor_1': DummyRPSRestrictor()\n",
    "}\n",
    "\n",
    "wrapper = MultiRestrictionWrapper(env, restrictors, \n",
    "                                  {'player_0': 'restrictor_1', 'player_1': 'restrictor_1'}, \n",
    "                                  preprocess_restrictor_observation_fns={'restrictor_0': restrictors['restrictor_0'].preprocess_observation})\n",
    "\n",
    "play(wrapper, create_policies(env, restrictors))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
