{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(f'{os.getcwd()}/../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Optional, Any, Set, Sequence\n",
    "from abc import ABC\n",
    "\n",
    "import functools\n",
    "import random\n",
    "\n",
    "import gymnasium\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import gymnasium.spaces\n",
    "from gymnasium.spaces import Discrete, Space, Dict\n",
    "\n",
    "from pettingzoo import AECEnv\n",
    "from pettingzoo.utils import agent_selector, wrappers\n",
    "from pettingzoo.test import api_test\n",
    "from pettingzoo.utils.env import AECIterable, AgentID, ActionType, ObsType\n",
    "\n",
    "from src.wrapper import RestrictionWrapper\n",
    "from examples.envs.rps import RPSEnvironment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Restriction(ABC, gymnasium.Space):\n",
    "    def __init__(self, base_space: gymnasium.Space, *, seed: int | np.random.Generator | None = None):\n",
    "        super().__init__(base_space.shape, base_space.dtype, seed)\n",
    "        self.base_space = base_space\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f'{self.__class__.__name__}'\n",
    "\n",
    "class DiscreteRestriction(Restriction, ABC):\n",
    "    def __init__(self, base_space: gymnasium.spaces.Discrete, *, seed: int | np.random.Generator | None = None):\n",
    "        super().__init__(base_space, seed=seed)\n",
    "\n",
    "class ContinuousRestriction(Restriction, ABC):\n",
    "    def __init__(self, base_space: gymnasium.spaces.Box, *, seed: int | np.random.Generator | None = None):\n",
    "        super().__init__(base_space, seed=seed)\n",
    "\n",
    "class DiscreteSetRestriction(DiscreteRestriction):\n",
    "    def __init__(self, base_space: gymnasium.spaces.Discrete, *, allowed_actions: Optional[Set[int]] = None, seed: int | np.random.Generator | None = None):\n",
    "        super().__init__(base_space, seed=seed)\n",
    "        \n",
    "        self.allowed_actions = allowed_actions if allowed_actions is not None else set(range(base_space.start, base_space.start + base_space.n))\n",
    "\n",
    "    @property\n",
    "    def is_np_flattenable(self) -> bool:\n",
    "        return True\n",
    "    \n",
    "    def sample(self) -> int:\n",
    "        return random.choice(tuple(self.allowed_actions))\n",
    "\n",
    "    def contains(self, x: int) -> bool:\n",
    "        return x in self.allowed_actions\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return f'{self.__class__.__name__}({self.allowed_actions})'\n",
    "\n",
    "class DiscreteVectorRestriction(DiscreteRestriction):\n",
    "    def __init__(self, base_space: gymnasium.spaces.Discrete, *, allowed_actions: Optional[np.ndarray[bool]] = None, seed: int | np.random.Generator | None = None):\n",
    "        super().__init__(base_space, seed=seed)\n",
    "        \n",
    "        self.allowed_actions = allowed_actions if allowed_actions is not None else set(range(base_space.start, base_space.start + base_space.n))\n",
    "\n",
    "    def __init__(self, allowed_actions: np.ndarray[bool], start: int = 0):\n",
    "        self.allowed_actions = allowed_actions\n",
    "        self.start = start\n",
    "\n",
    "    @property\n",
    "    def is_np_flattenable(self) -> bool:\n",
    "        return True\n",
    "    \n",
    "    def sample(self) -> int:\n",
    "        return self.start + random.choice(tuple(index for index, value in enumerate(self.allowed_actions) if value))\n",
    "\n",
    "    def contains(self, x: int) -> bool:\n",
    "        return self.allowed_actions[x - self.start]\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return f'{self.__class__.__name__}({self.allowed_actions})'\n",
    "\n",
    "class IntervalUnionRestriction(ContinuousRestriction):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Restrictor:\n",
    "    default_restriction_classes = {\n",
    "        gymnasium.spaces.Discrete: DiscreteSetRestriction,\n",
    "        gymnasium.spaces.Box: IntervalUnionRestriction\n",
    "    }\n",
    "\n",
    "    def __init__(self, env, restriction_classes=None) -> None:\n",
    "        self.action_spaces = {agent: env.action_space(agent) for agent in env.possible_agents}\n",
    "        self.restriction_classes = restriction_classes or self.default_restriction_classes\n",
    "\n",
    "class RPSRestrictor(Restrictor):\n",
    "    def __init__(self, env, restriction_classes=None) -> None:\n",
    "        super().__init__(env, restriction_classes=restriction_classes)\n",
    "\n",
    "        self.observation_space = Discrete(1)\n",
    "\n",
    "    def preprocess_observation(self, env):\n",
    "        # This functions 'flattens' the environment into a valid space while preserving all information that the restrictor needs\n",
    "        return {'agent': env.agent_selection, 'last_action': int(env.observe(env.possible_agents[1 - env.agent_name_mapping[env.agent_selection]]))}\n",
    "\n",
    "    def act(self, observation):\n",
    "        # Structure of observation is defined by self.preprocess_observation\n",
    "        agent, last_action = observation['agent'], observation['last_action']\n",
    "\n",
    "        return DiscreteSetRestriction(Discrete(3), allowed_actions={0, 1, 2} - {last_action})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class RestrictorActionSpace(ABC, gymnasium.Space):\n",
    "#     @property\n",
    "#     def is_np_flattenable(self) -> bool:\n",
    "#         return False\n",
    "\n",
    "#     def sample(self) -> Restriction:\n",
    "#         return DiscreteVectorRestriction(np.array([True]))\n",
    "        \n",
    "#     def contains(self, x: Restriction) -> bool:\n",
    "#         return True\n",
    "    \n",
    "#     def __repr__(self) -> str:\n",
    "#         return f'{self.__class__.__name__}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restriction_aware_random_policy(observation):\n",
    "    observation, restriction = observation['observation'], observation['restriction']\n",
    "    return restriction.sample()\n",
    "\n",
    "def create_policies(env, restrictor, restrictor_key='restrictor_0'):\n",
    "    return {**{ agent: restriction_aware_random_policy for agent in env.possible_agents }, restrictor_key: restrictor.act}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play(env, policies, *, max_iter=1_000, verbose=False):\n",
    "    env.reset()\n",
    "    env.render()\n",
    "\n",
    "    for agent in env.agent_iter():\n",
    "        observation, reward, termination, truncation, info = env.last()\n",
    "        if verbose:\n",
    "            print(f'{agent=}, {observation=}, {reward=}, {termination=}, {truncation=}, {info=}')\n",
    "\n",
    "        action = policies[agent](observation) if not termination and not truncation else None\n",
    "        if verbose:\n",
    "            print(f'{action=}')\n",
    "\n",
    "        env.step(action)\n",
    "    \n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "player_0: NONE, player_1: NONE\n",
      "player_0: ROCK, player_1: NONE\n",
      "player_0: ROCK, player_1: SCISSORS\n",
      "player_0: SCISSORS, player_1: NONE\n",
      "player_0: SCISSORS, player_1: PAPER\n",
      "player_0: PAPER, player_1: NONE\n",
      "player_0: PAPER, player_1: SCISSORS\n",
      "player_0: ROCK, player_1: NONE\n",
      "player_0: ROCK, player_1: PAPER\n",
      "player_0: PAPER, player_1: NONE\n",
      "player_0: PAPER, player_1: SCISSORS\n",
      "player_0: SCISSORS, player_1: NONE\n",
      "player_0: SCISSORS, player_1: PAPER\n",
      "player_0: ROCK, player_1: NONE\n",
      "player_0: ROCK, player_1: ROCK\n",
      "player_0: PAPER, player_1: NONE\n",
      "player_0: PAPER, player_1: SCISSORS\n",
      "player_0: ROCK, player_1: NONE\n",
      "player_0: ROCK, player_1: ROCK\n",
      "player_0: SCISSORS, player_1: NONE\n",
      "player_0: SCISSORS, player_1: PAPER\n",
      "Game over\n"
     ]
    }
   ],
   "source": [
    "env = RPSEnvironment(render_mode='human')\n",
    "restrictor = RPSRestrictor(env) # Restrictor blocks each player's last action\n",
    "wrapper = RestrictionWrapper(env, preprocess_restrictor_observation_fn=restrictor.preprocess_observation)\n",
    "\n",
    "play(wrapper, create_policies(env, restrictor))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
