{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "\n",
    "from src.utils import flatten\n",
    "from src.wrapper import RestrictionWrapper\n",
    "from examples.agents.td3 import TD3\n",
    "from examples.envs.navigation import NavigationEnvironment\n",
    "from examples.restrictors.navigation_restrictor import NavigationRestrictor\n",
    "from examples.utils import ReplayBuffer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Tested with seeds 44, 45, 46, 47, 48\n",
    "seed = 49\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "env_config = {\n",
    "    'HEIGHT': 15.0,\n",
    "    'WIDTH': 15.0,\n",
    "    'STEPS_PER_EPISODE': 40,\n",
    "    'ACTION_RANGE': 220,\n",
    "    'DT': 1.0,\n",
    "    'TIMESTEP_PENALTY_COEFFICIENT': 0.05,\n",
    "    'REWARD_COLLISION': -1.0,\n",
    "    'REWARD_GOAL': 5.0,\n",
    "    'REWARD_COEFFICIENT': 10.0,\n",
    "    'AGENT_RADIUS': 0.5,\n",
    "    'AGENT_PERSPECTIVE': 90,\n",
    "    'AGENT_STEP_SIZE': 1.0,\n",
    "    'AGENT_X': 1.5,\n",
    "    'AGENT_Y': 1.5,\n",
    "    'GOAL_RADIUS': 1.0,\n",
    "    'GOAL_X': 12.0,\n",
    "    'GOAL_y': 12.0\n",
    "}\n",
    "restrictor = NavigationRestrictor(0, [[5.0, 0.0], [0.0, 5.0]], 1.0, 0.2, 0.5, 50, 8, -110.0, 110.0)\n",
    "environment = NavigationEnvironment(env_config)\n",
    "\n",
    "restricted_environment = RestrictionWrapper(environment, restrictor)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "td3_config = {\n",
    "    'state_dim': 22,\n",
    "    'action_dim': 1,\n",
    "    'max_action': 110.0,\n",
    "    'discount': 0.99,\n",
    "    'tau': 0.005,\n",
    "    'policy_noise': 0.2,\n",
    "    'noise_clip:': 0.5,\n",
    "    'policy_freq': 2,\n",
    "    'exploration_noise': 0.2,\n",
    "    'batch_size': 256,\n",
    "    'train_after_timesteps': 2000,\n",
    "    'learning_rate_actor': 1e-5,\n",
    "    'learning_rate_critic': 1e-5\n",
    "}\n",
    "\n",
    "total_timesteps = 50000\n",
    "td3 = TD3(**td3_config)\n",
    "replay_buffer = ReplayBuffer(state_dim=td3_config['state_dim'], action_dim=td3_config['action_dim'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from src.restrictors import Restrictor\n",
    "\n",
    "\n",
    "def evaluate(eval_policy: TD3, eval_restrictor: Restrictor):\n",
    "    eval_env = RestrictionWrapper(NavigationEnvironment(env_config),\n",
    "                                  NavigationRestrictor(0, [[5.0, 0.0], [0.0, 5.0]], 1.0, 0.2, 0.5, 50, 8, -110.0, 110.0))\n",
    "    eval_reward = 0.0\n",
    "\n",
    "    eval_env.reset()\n",
    "    for eval_agent in eval_env.agent_iter():\n",
    "        obs, rew, term, trunc, inf = eval_env.last()\n",
    "        if eval_agent == 'agent_0':\n",
    "            eval_reward += rew\n",
    "            eval_action = eval_policy.select_action(flatten(eval_env.observation_space('agent_0'),\n",
    "                                                            obs, max_len=8, raise_error=False))\n",
    "        else:\n",
    "            eval_action = eval_restrictor.act(obs)\n",
    "\n",
    "        if term or trunc:\n",
    "            eval_action = None\n",
    "\n",
    "        eval_env.step(eval_action)\n",
    "\n",
    "    return eval_reward"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.73786972304547\n",
      "Finished episode 1 with reward -3.975812803695323\n",
      "Finished episode 2 with reward -3.79130942107132\n",
      "Finished episode 3 with reward 11.11701922710497\n",
      "Finished episode 4 with reward -9.45519746738855\n",
      "Finished episode 5 with reward -3.897859587698931\n",
      "Finished episode 6 with reward -8.16969296115076\n",
      "Finished episode 7 with reward 2.121757654473627\n",
      "2.73786972304547\n",
      "2.73786972304547\n",
      "Finished episode 8 with reward 3.5556299252238386\n",
      "Finished episode 9 with reward 1.81254924725854\n",
      "Finished episode 10 with reward 5.13586021148406\n",
      "Finished episode 11 with reward 2.58650682504495\n",
      "Finished episode 12 with reward 0.1509789682882301\n",
      "Finished episode 13 with reward -7.3088956545113\n",
      "2.73786972304547\n",
      "2.73786972304547\n",
      "Finished episode 14 with reward 53.644894987402616\n",
      "Finished episode 15 with reward 15.544251510981411\n",
      "2.73786972304547\n",
      "Finished episode 16 with reward 2.48394841219308\n",
      "2.73786972304547\n",
      "Finished episode 17 with reward 3.639142850750213\n",
      "Finished episode 18 with reward 8.448335166431349\n",
      "Finished episode 19 with reward 3.6548943449744\n",
      "Finished episode 20 with reward 15.850685073812357\n",
      "Finished episode 21 with reward -5.44340957064155\n",
      "Finished episode 22 with reward -9.04177695993479\n",
      "Finished episode 23 with reward 1.48565818690822\n",
      "Finished episode 24 with reward 9.872220427987191\n",
      "2.73786972304547\n",
      "2.73786972304547\n",
      "Finished episode 25 with reward 2.168404093828439\n",
      "Finished episode 26 with reward 8.698047315846459\n",
      "Finished episode 27 with reward 5.93670006980823\n",
      "Finished episode 28 with reward 3.49270137045756\n",
      "Finished episode 29 with reward 9.068314942065701\n",
      "Finished episode 30 with reward 15.105102915593072\n",
      "2.73786972304547\n",
      "2.73786972304547\n",
      "Finished episode 31 with reward -22.06268290780085\n",
      "Finished episode 32 with reward -8.84920210676669\n",
      "Finished episode 33 with reward -9.86550389483178\n",
      "Finished episode 34 with reward 18.683726361540696\n",
      "Finished episode 35 with reward 4.65739071180378\n",
      "2.73786972304547\n",
      "2.73786972304547\n",
      "Finished episode 36 with reward -2.21437617332284\n",
      "Finished episode 37 with reward 9.130972426290061\n",
      "Finished episode 38 with reward 0.10425188982863998\n",
      "Finished episode 39 with reward 3.80443226871511\n",
      "Finished episode 40 with reward 5.355997767677289\n",
      "Finished episode 41 with reward 14.681232285406578\n",
      "Finished episode 42 with reward -0.15470672077474001\n",
      "Finished episode 43 with reward 10.116249628087449\n",
      "2.73786972304547\n",
      "2.73786972304547\n",
      "Finished episode 44 with reward 78.66685313810856\n",
      "Finished episode 45 with reward 7.67020331055666\n",
      "Finished episode 46 with reward -7.4985911157764\n",
      "2.73786972304547\n",
      "2.73786972304547\n",
      "Finished episode 47 with reward -5.921209369639258\n",
      "Finished episode 48 with reward 2.5290941052589497\n",
      "Finished episode 49 with reward -15.855181806882348\n",
      "Finished episode 50 with reward -4.89291244638663\n",
      "Finished episode 51 with reward -9.98000245930726\n",
      "Finished episode 52 with reward 23.656986177585104\n",
      "Finished episode 53 with reward -7.65115719957136\n",
      "2.73786972304547\n",
      "2.73786972304547\n",
      "Finished episode 54 with reward -9.25704173180538\n",
      "Finished episode 55 with reward -13.271624880217662\n",
      "Finished episode 56 with reward 0.45550035706214054\n",
      "Finished episode 57 with reward 24.73960567689094\n",
      "Finished episode 58 with reward 0.5614237266781004\n",
      "Finished episode 59 with reward -6.6889094137449\n",
      "Finished episode 60 with reward 5.4088239599113805\n",
      "Finished episode 61 with reward -7.572947492249548\n",
      "Finished episode 62 with reward -4.58004668938184\n",
      "2.73786972304547\n",
      "Finished episode 63 with reward 1.85298886414198\n",
      "Finished episode 64 with reward 25.664473093265613\n",
      "Finished episode 65 with reward 8.5218670747592\n",
      "2.73786972304547\n",
      "2.73786972304547\n",
      "Finished episode 66 with reward 77.81997527555369\n",
      "Finished episode 67 with reward 12.800278686618029\n",
      "Finished episode 68 with reward 18.38392850699423\n",
      "2.73786972304547\n",
      "2.73786972304547\n",
      "Finished episode 69 with reward -0.7674770843547796\n",
      "Finished episode 70 with reward 15.23945432039508\n",
      "Finished episode 71 with reward -4.41202489394007\n",
      "Finished episode 72 with reward 2.891083300138848\n",
      "2.73786972304547\n",
      "Finished episode 73 with reward 16.771860106457055\n",
      "2.73786972304547\n",
      "Finished episode 74 with reward -5.595666510701366\n",
      "Finished episode 75 with reward -10.08058093431345\n",
      "2.73786972304547\n",
      "2.73786972304547\n",
      "Finished episode 76 with reward 10.445153890068383\n",
      "Finished episode 77 with reward -0.49075749883214004\n",
      "Finished episode 78 with reward -2.4758952297363397\n",
      "Finished episode 79 with reward 32.03653451623518\n",
      "Finished episode 80 with reward 10.767729723403402\n",
      "2.73786972304547\n",
      "Finished episode 81 with reward -6.36833952873025\n",
      "Finished episode 82 with reward -8.87107634191983\n",
      "Finished episode 83 with reward 11.036943305218212\n",
      "Finished episode 84 with reward 26.81910710432511\n",
      "Finished episode 85 with reward 15.8849909109395\n",
      "Finished episode 86 with reward 5.27392533670172\n",
      "2.73786972304547\n",
      "2.73786972304547\n",
      "Finished episode 87 with reward 18.674093484326036\n",
      "Finished episode 88 with reward 17.5170829731843\n",
      "Finished episode 89 with reward -3.99106412056014\n",
      "Finished episode 90 with reward 33.09490665396602\n",
      "2.73786972304547\n",
      "2.73786972304547\n",
      "Finished episode 91 with reward 45.83506419701032\n",
      "2.73786972304547\n",
      "2.73786972304547\n",
      "Finished episode 92 with reward 71.83847114623214\n",
      "Finished episode 93 with reward 14.208764235220956\n",
      "2.73786972304547\n",
      "2.73786972304547\n",
      "Finished episode 94 with reward -11.792283092413568\n",
      "Finished episode 95 with reward 19.054254812491163\n",
      "Finished episode 96 with reward 3.70759794069055\n",
      "Finished episode 97 with reward 22.46208224389227\n",
      "Finished episode 98 with reward -4.511920358356949\n",
      "2.73786972304547\n",
      "2.73786972304547\n",
      "Finished episode 99 with reward 6.99643740179552\n",
      "Finished episode 100 with reward -10.80876880015505\n",
      "Finished episode 101 with reward -10.09806888489891\n",
      "Finished episode 102 with reward 2.93371752240633\n",
      "Finished episode 103 with reward 0.2668813483054624\n",
      "Finished episode 104 with reward -4.29845711894802\n",
      "Finished episode 105 with reward -1.1839720845329103\n",
      "2.73786972304547\n",
      "2.73786972304547\n",
      "Finished episode 106 with reward -15.447905911004362\n",
      "Finished episode 107 with reward -8.46279498496602\n",
      "Finished episode 108 with reward -9.85071299081005\n",
      "Finished episode 109 with reward 5.93667388073689\n",
      "Finished episode 110 with reward 7.87016082350992\n",
      "2.73786972304547\n",
      "Finished episode 111 with reward -9.12384286101844\n",
      "2.73786972304547\n",
      "Finished episode 112 with reward 18.09635193113682\n",
      "Finished episode 113 with reward 3.2822854223794495\n",
      "Finished episode 114 with reward 14.280294829881747\n",
      "Finished episode 115 with reward -3.8863628051609886\n",
      "Finished episode 116 with reward 1.5086195496213102\n",
      "Finished episode 117 with reward 1.7087445314193\n",
      "Finished episode 118 with reward 7.229168886247789\n",
      "2.73786972304547\n",
      "2.73786972304547\n",
      "Finished episode 119 with reward 44.340010571961535\n",
      "Finished episode 120 with reward -1.92578650327627\n",
      "2.73786972304547\n",
      "2.73786972304547\n",
      "Finished episode 121 with reward 48.018789594129274\n",
      "Finished episode 122 with reward 4.04788891400842\n",
      "2.73786972304547\n",
      "2.73786972304547\n",
      "Finished episode 123 with reward 1.3326908437528608\n",
      "Finished episode 124 with reward 16.20864100699523\n",
      "Finished episode 125 with reward 7.1934078995847095\n",
      "Finished episode 126 with reward -8.021881588956731\n",
      "Finished episode 127 with reward -3.26737618925395\n",
      "Finished episode 128 with reward -7.12760604300545\n",
      "2.73786972304547\n",
      "2.73786972304547\n",
      "Finished episode 129 with reward 2.638402105559625\n",
      "2.73786972304547\n",
      "2.73786972304547\n",
      "Finished episode 130 with reward 66.31315325759823\n",
      "Finished episode 131 with reward 14.19578021996508\n",
      "Finished episode 132 with reward -7.42856756978135\n",
      "Finished episode 133 with reward -6.74944825238356\n",
      "Finished episode 134 with reward -8.6353077889264\n",
      "Finished episode 135 with reward 3.767177159586561\n",
      "Finished episode 136 with reward 18.82695193466278\n",
      "2.73786972304547\n",
      "2.73786972304547\n",
      "Finished episode 137 with reward 43.963569817220204\n",
      "Finished episode 138 with reward 24.563051399909078\n",
      "Finished episode 139 with reward 6.8427238212049595\n",
      "2.73786972304547\n",
      "Finished episode 140 with reward -5.80064661389157\n",
      "Finished episode 141 with reward -3.92843280704771\n",
      "Finished episode 142 with reward 47.42443407505205\n",
      "Finished episode 143 with reward -5.3192384963049\n",
      "2.73786972304547\n",
      "2.73786972304547\n",
      "Finished episode 144 with reward -20.584445422078367\n",
      "Finished episode 145 with reward 10.428564988767297\n",
      "Finished episode 146 with reward 79.3730220455172\n",
      "2.73786972304547\n",
      "2.73786972304547\n",
      "Finished episode 147 with reward 10.439877974201709\n",
      "Finished episode 148 with reward 8.6228945669442\n",
      "Finished episode 149 with reward 1.9809446071555001\n",
      "Finished episode 150 with reward 6.641722394039205\n",
      "Finished episode 151 with reward 7.8206684582152\n",
      "Finished episode 152 with reward 5.36494891511067\n",
      "2.73786972304547\n",
      "2.73786972304547\n",
      "Finished episode 153 with reward 5.53488559975375\n",
      "Finished episode 154 with reward -6.45092180077596\n",
      "Finished episode 155 with reward -5.11791910592761\n",
      "Finished episode 156 with reward 21.174229665307433\n",
      "Finished episode 157 with reward 5.861027826010883\n",
      "Finished episode 158 with reward -9.414804195374302\n",
      "Finished episode 159 with reward 12.702686789887899\n",
      "2.73786972304547\n",
      "2.73786972304547\n",
      "Finished episode 160 with reward 6.567168468381598\n",
      "Finished episode 161 with reward 9.565649256081684\n",
      "2.73786972304547\n",
      "2.73786972304547\n",
      "Finished episode 162 with reward 3.350699199990272\n",
      "Finished episode 163 with reward 6.67768359888818\n",
      "Finished episode 164 with reward 1.0499871195080601\n",
      "2.73786972304547\n",
      "2.73786972304547\n",
      "Finished episode 165 with reward 23.31512832450187\n",
      "Finished episode 166 with reward 0.2587951760379301\n",
      "Finished episode 167 with reward 90.7009754027375\n",
      "Finished episode 168 with reward -14.240273424243542\n",
      "Finished episode 169 with reward -8.60343182814811\n",
      "Finished episode 170 with reward -4.87132172631821\n",
      "2.73786972304547\n",
      "2.73786972304547\n",
      "Finished episode 171 with reward 19.291915383874436\n",
      "Finished episode 172 with reward -2.3822357766398863\n",
      "Finished episode 173 with reward 2.5604200122226\n",
      "2.73786972304547\n",
      "2.73786972304547\n",
      "Finished episode 174 with reward 8.221482050440171\n",
      "Finished episode 175 with reward 19.249046696291575\n",
      "Finished episode 176 with reward -7.34836833410914\n",
      "Finished episode 177 with reward 0.4790556672083699\n",
      "Finished episode 178 with reward 5.0027102608195\n",
      "Finished episode 179 with reward 9.938661590844855\n",
      "2.73786972304547\n",
      "2.73786972304547\n",
      "Finished episode 180 with reward 7.061755292840271\n",
      "Finished episode 181 with reward -0.4358011467381111\n",
      "Finished episode 182 with reward 13.67060768906802\n",
      "Finished episode 183 with reward 6.7471635609547995\n",
      "Finished episode 184 with reward -9.4262230230339\n",
      "Finished episode 185 with reward 15.868400981460013\n",
      "2.73786972304547\n",
      "2.73786972304547\n",
      "Finished episode 186 with reward -2.8106057979879875\n",
      "Finished episode 187 with reward -8.55928029707919\n",
      "Finished episode 188 with reward -3.48008909934766\n",
      "Finished episode 189 with reward 107.59867464100216\n",
      "2.73786972304547\n",
      "Finished episode 190 with reward -9.99030717818356\n",
      "Finished episode 191 with reward 11.331390439532303\n",
      "Finished episode 192 with reward 8.59464748065069\n",
      "Finished episode 193 with reward 2.93853185298388\n",
      "2.94449488714288\n",
      "2.94449488714288\n",
      "Finished episode 194 with reward -19.649113850434794\n",
      "Finished episode 195 with reward 1.5426972326383597\n",
      "Finished episode 196 with reward 2.93853185298388\n",
      "Finished episode 197 with reward 2.93853185298388\n",
      "Finished episode 198 with reward 2.93853185298388\n",
      "2.94090620905107\n",
      "2.94090620905107\n",
      "Finished episode 199 with reward -30.701240985484905\n",
      "Finished episode 200 with reward 2.93853185298388\n",
      "Finished episode 201 with reward 2.93853185298388\n",
      "Finished episode 202 with reward 2.93853185298388\n",
      "Finished episode 203 with reward 2.93853185298388\n",
      "Finished episode 204 with reward 5.532762578220032\n",
      "2.94075193206357\n",
      "2.94075193206357\n",
      "Finished episode 205 with reward -25.846981500437757\n",
      "Finished episode 206 with reward 2.93853185298388\n",
      "Finished episode 207 with reward 2.93853185298388\n",
      "Finished episode 208 with reward 3.81265380215605\n",
      "Finished episode 209 with reward 0.28167533581029947\n",
      "Finished episode 210 with reward 2.93853185298388\n",
      "2.94080389916427\n",
      "2.94080389916427\n",
      "Finished episode 211 with reward 2.93853185298388\n",
      "Finished episode 212 with reward 3.6296591358905204\n",
      "Finished episode 213 with reward -14.699468868286282\n",
      "Finished episode 214 with reward 3.4117969467123404\n",
      "2.94090783301387\n",
      "2.94090783301387\n",
      "Finished episode 215 with reward 2.93853185298388\n",
      "Finished episode 216 with reward 2.93853185298388\n",
      "Finished episode 217 with reward 2.93853185298388\n",
      "Finished episode 218 with reward 2.93853185298388\n",
      "Finished episode 219 with reward 2.35654245884876\n",
      "Finished episode 220 with reward 2.93853185298388\n",
      "Finished episode 221 with reward 5.54142266724111\n",
      "Finished episode 222 with reward 2.93853185298388\n",
      "Finished episode 223 with reward 2.93853185298388\n",
      "Finished episode 224 with reward 2.93853185298388\n",
      "Finished episode 225 with reward 3.58676387846012\n",
      "Finished episode 226 with reward 2.93853185298388\n",
      "Finished episode 227 with reward 2.93853185298388\n",
      "2.94106941673897\n",
      "2.94106941673897\n",
      "Finished episode 228 with reward -39.31800077858324\n",
      "Finished episode 229 with reward 2.93853185298388\n",
      "Finished episode 230 with reward 2.93853185298388\n",
      "Finished episode 231 with reward 2.93853185298388\n",
      "Finished episode 232 with reward 2.93853185298388\n",
      "Finished episode 233 with reward 2.93853185298388\n",
      "Finished episode 234 with reward 4.01304732807531\n",
      "2.941317067986\n",
      "2.941317067986\n",
      "Finished episode 235 with reward 2.93853185298388\n",
      "Finished episode 236 with reward 2.93853185298388\n",
      "Finished episode 237 with reward 2.93853185298388\n",
      "Finished episode 238 with reward 2.93853185298388\n",
      "Finished episode 239 with reward 2.93853185298388\n",
      "Finished episode 240 with reward -1.6816085797809315\n",
      "Finished episode 241 with reward 2.93853185298388\n",
      "Finished episode 242 with reward 2.93853185298388\n",
      "Finished episode 243 with reward 2.93853185298388\n",
      "Finished episode 244 with reward 2.1557627557886683\n",
      "2.9417084327217\n",
      "2.9417084327217\n",
      "Finished episode 245 with reward -1.0457218358024605\n",
      "Finished episode 246 with reward 2.93853185298388\n",
      "Finished episode 247 with reward 2.93853185298388\n",
      "Finished episode 248 with reward 2.93853185298388\n",
      "2.94231576565028\n",
      "2.94231576565028\n",
      "Finished episode 249 with reward -18.507941916126605\n",
      "Finished episode 250 with reward 2.93853185298388\n",
      "Finished episode 251 with reward -31.32623553966398\n",
      "2.9434573133097\n",
      "2.9434573133097\n",
      "Finished episode 252 with reward -3.2240668099729692\n",
      "Finished episode 253 with reward 2.93853185298388\n",
      "2.94595293211731\n",
      "2.94595293211731\n",
      "Finished episode 254 with reward -27.034005358901602\n",
      "2.95406384961003\n",
      "Finished episode 255 with reward -31.630927802830996\n",
      "Finished episode 256 with reward 2.93853185298388\n",
      "Finished episode 257 with reward 5.302575194789\n",
      "Finished episode 258 with reward 4.30729928362346\n",
      "Finished episode 259 with reward 3.2826804507457776\n",
      "Finished episode 260 with reward 5.26306492053642\n",
      "3.2535665900825004\n",
      "3.2535665900825004\n",
      "Finished episode 261 with reward -28.808637776937957\n",
      "3.188972123546298\n",
      "3.188972123546298\n",
      "Finished episode 262 with reward 6.188798753811632\n",
      "45.924476988773556\n",
      "Finished episode 263 with reward 24.965935209505957\n",
      "45.924476988773556\n",
      "Finished episode 264 with reward -27.519704062048223\n",
      "35.227610217144445\n",
      "35.227610217144445\n",
      "Finished episode 265 with reward 32.52019306758301\n",
      "83.75958606481474\n",
      "83.75958606481474\n",
      "Finished episode 266 with reward -4.9791867966183485\n",
      "Finished episode 267 with reward 6.982440870129957\n",
      "107.84140011789277\n",
      "Finished episode 268 with reward 69.89323275459643\n",
      "107.84140011789277\n",
      "Finished episode 269 with reward 18.828718376070313\n",
      "Finished episode 270 with reward 70.12585956932239\n",
      "65.6846262696875\n",
      "65.6846262696875\n",
      "Finished episode 271 with reward 39.43720427152647\n",
      "29.52711273174436\n",
      "29.52711273174436\n",
      "Finished episode 272 with reward 16.18830067598561\n",
      "Finished episode 273 with reward 26.782774139027595\n",
      "13.992642207006035\n",
      "13.992642207006035\n",
      "Finished episode 274 with reward 53.69042008220504\n",
      "Finished episode 275 with reward 21.471564676071907\n",
      "Finished episode 276 with reward 17.389000310744976\n",
      "68.59482808905413\n",
      "68.59482808905413\n",
      "Finished episode 277 with reward 106.43258320868645\n",
      "Finished episode 278 with reward 12.095597442020791\n",
      "28.261759967702343\n",
      "28.261759967702343\n",
      "Finished episode 279 with reward 80.45949075295651\n",
      "Finished episode 280 with reward 83.1320791953271\n",
      "57.576867784295594\n",
      "57.576867784295594\n",
      "Finished episode 281 with reward 87.365542903048\n",
      "95.61917755688118\n",
      "95.61917755688118\n",
      "Finished episode 282 with reward 41.751314932329606\n",
      "Finished episode 283 with reward 24.162282180893655\n",
      "68.34287791582574\n",
      "68.34287791582574\n",
      "Finished episode 284 with reward 114.53192000919384\n",
      "Finished episode 285 with reward 92.92367146123223\n",
      "65.896040507221\n",
      "65.896040507221\n",
      "Finished episode 286 with reward 27.933246206306116\n",
      "Finished episode 287 with reward 30.607218377728067\n",
      "69.87082624203647\n",
      "69.87082624203647\n",
      "Finished episode 288 with reward 82.56219995860717\n",
      "Finished episode 289 with reward 55.38176058061987\n",
      "58.224790783584\n",
      "58.224790783584\n",
      "Finished episode 290 with reward 77.37003509701731\n",
      "Finished episode 291 with reward 63.45935685762666\n",
      "Finished episode 292 with reward -0.7380352385412596\n",
      "105.80325273793115\n",
      "105.80325273793115\n",
      "Finished episode 293 with reward 103.54010433008274\n",
      "125.1194062295684\n",
      "125.1194062295684\n",
      "Finished episode 294 with reward 97.83263054735579\n",
      "Finished episode 295 with reward 59.85738520090785\n",
      "103.80504373840147\n",
      "103.80504373840147\n",
      "Finished episode 296 with reward 54.18508711691486\n",
      "Finished episode 297 with reward 85.55151271053967\n",
      "46.99922969610655\n",
      "46.99922969610655\n",
      "Finished episode 298 with reward 59.75834292469226\n",
      "Finished episode 299 with reward 119.51592776449307\n",
      "92.96214338863685\n",
      "92.96214338863685\n",
      "Finished episode 300 with reward 79.09626682460303\n",
      "Finished episode 301 with reward 88.60719849670099\n",
      "124.99054783765189\n",
      "124.99054783765189\n",
      "Finished episode 302 with reward 119.54103227047852\n",
      "Finished episode 303 with reward 114.04148677073233\n",
      "124.77149283137001\n",
      "124.77149283137001\n",
      "Finished episode 304 with reward 129.62941323421558\n",
      "Finished episode 305 with reward 103.09250167073583\n",
      "130.01585196343\n",
      "130.01585196343\n",
      "Finished episode 306 with reward 130.5802796867519\n",
      "Finished episode 307 with reward 128.47170680237633\n",
      "125.8854948841272\n",
      "125.8854948841272\n",
      "Finished episode 308 with reward 127.13562481965161\n",
      "Finished episode 309 with reward 104.91406246298375\n",
      "Finished episode 310 with reward 125.41552215342399\n",
      "127.2006234611998\n",
      "127.2006234611998\n",
      "Finished episode 311 with reward 114.74362974291387\n",
      "130.76288477852694\n",
      "130.76288477852694\n",
      "Finished episode 312 with reward 121.51552292676327\n",
      "Finished episode 313 with reward 121.67988915784713\n",
      "Finished episode 314 with reward 128.52004788447596\n",
      "124.17055413973844\n",
      "124.17055413973844\n",
      "Finished episode 315 with reward 123.16573173474092\n",
      "Finished episode 316 with reward 127.25671882680372\n",
      "131.2390175951793\n",
      "Finished episode 317 with reward 123.70164189226756\n",
      "Finished episode 318 with reward 124.18158359545792\n",
      "Finished episode 319 with reward 128.78644755612572\n",
      "125.91292497026008\n",
      "125.91292497026008\n",
      "Finished episode 320 with reward 126.08639607396569\n",
      "Finished episode 321 with reward 123.05291213074995\n",
      "118.83139302847277\n",
      "Finished episode 322 with reward 129.2823437519909\n",
      "Finished episode 323 with reward 128.34647822240947\n",
      "Finished episode 324 with reward 121.37273922526316\n",
      "125.95906025221092\n",
      "125.95906025221092\n",
      "Finished episode 325 with reward 123.39309697523127\n",
      "Finished episode 326 with reward 127.61829993129246\n",
      "125.48583922564698\n",
      "125.48583922564698\n",
      "Finished episode 327 with reward 126.093272681017\n",
      "Finished episode 328 with reward 126.34192267936872\n",
      "Finished episode 329 with reward 130.4418761960597\n",
      "111.10422058400384\n",
      "111.10422058400384\n",
      "Finished episode 330 with reward 103.22096382933054\n",
      "Finished episode 331 with reward 129.4855350366779\n",
      "128.33498769651737\n",
      "128.33498769651737\n",
      "Finished episode 332 with reward 124.19879212231824\n",
      "Finished episode 333 with reward 110.15403105293294\n",
      "124.20691488336304\n",
      "124.20691488336304\n",
      "Finished episode 334 with reward 114.58289465743222\n",
      "Finished episode 335 with reward 122.84767063726326\n",
      "81.57723760448195\n",
      "Finished episode 336 with reward 127.21274803019153\n",
      "Finished episode 337 with reward 98.39409562701658\n",
      "Finished episode 338 with reward 128.69282038045816\n",
      "123.33540273339337\n",
      "123.33540273339337\n",
      "Finished episode 339 with reward 101.01768886096417\n",
      "123.1930062008333\n",
      "123.1930062008333\n",
      "Finished episode 340 with reward 114.41091108359429\n",
      "Finished episode 341 with reward 103.49580023745692\n",
      "115.72454829542328\n",
      "115.72454829542328\n",
      "Finished episode 342 with reward 87.94889361087587\n",
      "Finished episode 343 with reward 115.49651866879789\n",
      "115.62173968225535\n",
      "115.62173968225535\n",
      "Finished episode 344 with reward 117.42059193762009\n",
      "Finished episode 345 with reward 118.98691641968296\n",
      "123.16730390672434\n",
      "123.16730390672434\n",
      "Finished episode 346 with reward 115.2415321275524\n",
      "Finished episode 347 with reward 100.57410981330399\n",
      "117.33173273168549\n",
      "117.33173273168549\n",
      "Finished episode 348 with reward 94.03018730761532\n",
      "Finished episode 349 with reward 87.75909165013775\n",
      "114.16727588300715\n",
      "114.16727588300715\n",
      "Finished episode 350 with reward 116.50616776167246\n",
      "119.98863232757927\n",
      "119.98863232757927\n",
      "Finished episode 351 with reward 102.26265631826782\n",
      "Finished episode 352 with reward 117.59420690991149\n",
      "115.30508434377114\n",
      "115.30508434377114\n",
      "Finished episode 353 with reward 120.45433281999782\n",
      "Finished episode 354 with reward 121.51163963164875\n",
      "99.89694654426329\n",
      "99.89694654426329\n",
      "Finished episode 355 with reward 102.25230129669093\n",
      "Finished episode 356 with reward 120.40212660537658\n",
      "113.75160131535205\n",
      "113.75160131535205\n",
      "Finished episode 357 with reward 122.62048718269227\n",
      "Finished episode 358 with reward 118.67298484473963\n",
      "103.9000205620733\n",
      "103.9000205620733\n",
      "Finished episode 359 with reward 115.80124086328178\n",
      "Finished episode 360 with reward 123.63323143837214\n",
      "120.68680932351118\n",
      "120.68680932351118\n",
      "Finished episode 361 with reward 114.9707986403123\n",
      "Finished episode 362 with reward 117.08863664689969\n",
      "112.33673480044395\n",
      "112.33673480044395\n",
      "Finished episode 363 with reward 102.21846250906597\n",
      "Finished episode 364 with reward 117.43470009456746\n",
      "114.45700270218445\n",
      "114.45700270218445\n",
      "Finished episode 365 with reward 123.95861796173753\n",
      "Finished episode 366 with reward 119.23448125788697\n",
      "112.96581537961364\n",
      "112.96581537961364\n",
      "Finished episode 367 with reward 117.48661390796671\n",
      "Finished episode 368 with reward 101.5097518458653\n",
      "113.69531587765835\n",
      "113.69531587765835\n",
      "Finished episode 369 with reward 88.18426264743121\n",
      "Finished episode 370 with reward 104.63607596938279\n",
      "93.83636390504907\n",
      "93.83636390504907\n",
      "Finished episode 371 with reward 105.37685280577062\n",
      "100.42443716648125\n",
      "100.42443716648125\n",
      "Finished episode 372 with reward 115.19714818228611\n",
      "Finished episode 373 with reward 87.51565320593674\n",
      "116.46874469947043\n",
      "116.46874469947043\n",
      "Finished episode 374 with reward 120.46846777382378\n",
      "Finished episode 375 with reward 121.89461571643233\n",
      "101.5945040485572\n",
      "101.5945040485572\n",
      "Finished episode 376 with reward 115.44728811026822\n",
      "Finished episode 377 with reward 117.3713855643666\n",
      "115.22076212925542\n",
      "115.22076212925542\n",
      "Finished episode 378 with reward 124.64007501840817\n",
      "Finished episode 379 with reward 124.65655314011786\n",
      "114.7852569177772\n",
      "114.7852569177772\n",
      "Finished episode 380 with reward 83.94534283571286\n",
      "Finished episode 381 with reward 121.73371791721502\n",
      "115.51237649844272\n",
      "115.51237649844272\n",
      "Finished episode 382 with reward 118.16166910031681\n",
      "Finished episode 383 with reward 119.2222332750473\n",
      "93.14809166337376\n",
      "93.14809166337376\n",
      "Finished episode 384 with reward 110.07062322376574\n",
      "Finished episode 385 with reward 124.40884126690149\n",
      "115.10520185278735\n",
      "115.10520185278735\n",
      "Finished episode 386 with reward 92.28881067466399\n",
      "115.5036242423774\n",
      "115.5036242423774\n",
      "Finished episode 387 with reward 98.39896428848796\n",
      "Finished episode 388 with reward 116.05811182148358\n",
      "113.64291164089654\n",
      "113.64291164089654\n",
      "Finished episode 389 with reward 113.13284561562645\n",
      "Finished episode 390 with reward 121.58422416672084\n",
      "114.87749528189471\n",
      "114.87749528189471\n",
      "Finished episode 391 with reward 118.68765967255091\n",
      "Finished episode 392 with reward 122.211338170601\n",
      "117.63849130620616\n",
      "117.63849130620616\n",
      "Finished episode 393 with reward 104.83680569289572\n",
      "Finished episode 394 with reward 120.34527637633143\n",
      "112.04390398387679\n",
      "112.04390398387679\n",
      "Finished episode 395 with reward 118.83677188413596\n",
      "Finished episode 396 with reward 0.6643016708192402\n",
      "Finished episode 397 with reward 116.96071543324267\n",
      "113.36741532631858\n",
      "113.36741532631858\n",
      "Finished episode 398 with reward 113.28581049941621\n",
      "111.24123747252295\n",
      "111.24123747252295\n",
      "Finished episode 399 with reward 104.76049905297727\n",
      "Finished episode 400 with reward 120.67869686176093\n",
      "116.56790594227844\n",
      "116.56790594227844\n",
      "Finished episode 401 with reward 117.03724196172088\n",
      "Finished episode 402 with reward 96.52219284585205\n",
      "114.61227993426021\n",
      "114.61227993426021\n",
      "Finished episode 403 with reward 119.93802610425237\n",
      "Finished episode 404 with reward 102.12197894314183\n",
      "112.81170055852786\n",
      "112.81170055852786\n",
      "Finished episode 405 with reward 123.18895547772264\n",
      "Finished episode 406 with reward 100.7185029026944\n",
      "110.81569385730438\n",
      "110.81569385730438\n",
      "Finished episode 407 with reward 114.72675215815953\n",
      "Finished episode 408 with reward 122.85126325534657\n",
      "113.78950742545354\n",
      "113.78950742545354\n",
      "Finished episode 409 with reward 115.18221868447623\n",
      "96.9282804825138\n",
      "Finished episode 410 with reward 121.60209882071972\n",
      "96.9282804825138\n",
      "Finished episode 411 with reward 120.0238465227668\n",
      "112.46382874809021\n",
      "112.46382874809021\n",
      "Finished episode 412 with reward 120.28307285975265\n",
      "Finished episode 413 with reward 117.97213492502023\n",
      "114.06341881295437\n",
      "114.06341881295437\n",
      "Finished episode 414 with reward 119.70897275360514\n",
      "Finished episode 415 with reward 81.49683233596116\n",
      "112.93979458054865\n",
      "112.93979458054865\n",
      "Finished episode 416 with reward 119.28180786725761\n",
      "Finished episode 417 with reward 121.63846030542965\n",
      "112.16532527173784\n",
      "112.16532527173784\n",
      "Finished episode 418 with reward 106.48350578439818\n",
      "Finished episode 419 with reward 118.65840427350322\n",
      "111.60695950084194\n",
      "111.60695950084194\n",
      "Finished episode 420 with reward 116.81640209455234\n",
      "Finished episode 421 with reward 120.22963258451976\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 53\u001B[0m\n\u001B[1;32m     50\u001B[0m         restricted_environment\u001B[38;5;241m.\u001B[39mstep(action)\n\u001B[1;32m     52\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m training_timesteps \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m50\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m---> 53\u001B[0m             \u001B[38;5;28mprint\u001B[39m(\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtd3\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrestrictor\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     55\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFinished episode \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepisode_num\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m with reward \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepisode_reward\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     57\u001B[0m restricted_environment\u001B[38;5;241m.\u001B[39mclose()\n",
      "Cell \u001B[0;32mIn[5], line 17\u001B[0m, in \u001B[0;36mevaluate\u001B[0;34m(eval_policy, eval_restrictor)\u001B[0m\n\u001B[1;32m     14\u001B[0m     eval_action \u001B[38;5;241m=\u001B[39m eval_policy\u001B[38;5;241m.\u001B[39mselect_action(flatten(eval_env\u001B[38;5;241m.\u001B[39mobservation_space(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124magent_0\u001B[39m\u001B[38;5;124m'\u001B[39m),\n\u001B[1;32m     15\u001B[0m                                                     obs, max_len\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m8\u001B[39m, raise_error\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m))\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 17\u001B[0m     eval_action \u001B[38;5;241m=\u001B[39m \u001B[43meval_restrictor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mact\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m term \u001B[38;5;129;01mor\u001B[39;00m trunc:\n\u001B[1;32m     20\u001B[0m     eval_action \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/test/hicss-2024/examples/restrictors/navigation_restrictor.py:322\u001B[0m, in \u001B[0;36mNavigationRestrictor.act\u001B[0;34m(self, observation)\u001B[0m\n\u001B[1;32m    317\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(obstacle, Obstacle):\n\u001B[1;32m    318\u001B[0m     obstacle \u001B[38;5;241m=\u001B[39m obstacle\u001B[38;5;241m.\u001B[39mcollision_area(\u001B[38;5;28mfloat\u001B[39m(agent\u001B[38;5;241m.\u001B[39mradius))\n\u001B[1;32m    320\u001B[0m is_in_collision_area \u001B[38;5;241m=\u001B[39m obstacle\u001B[38;5;241m.\u001B[39mcontains(\n\u001B[1;32m    321\u001B[0m     Point(\u001B[38;5;28mfloat\u001B[39m(agent\u001B[38;5;241m.\u001B[39mx), \u001B[38;5;28mfloat\u001B[39m(agent\u001B[38;5;241m.\u001B[39my))) \u001B[38;5;129;01mor\u001B[39;00m obstacle\u001B[38;5;241m.\u001B[39mboundary\u001B[38;5;241m.\u001B[39mcontains(\n\u001B[0;32m--> 322\u001B[0m     \u001B[43mPoint\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mfloat\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43magent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mfloat\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43magent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    324\u001B[0m obstacle_step_circle_intersection \u001B[38;5;241m=\u001B[39m step_circle\u001B[38;5;241m.\u001B[39mintersection(\n\u001B[1;32m    325\u001B[0m     obstacle) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_in_collision_area \u001B[38;5;28;01melse\u001B[39;00m (\n\u001B[1;32m    326\u001B[0m     step_circle\u001B[38;5;241m.\u001B[39mboundary\u001B[38;5;241m.\u001B[39mdifference(obstacle))\n\u001B[1;32m    328\u001B[0m \u001B[38;5;66;03m# If intersection consists of multiple parts, iterate through them\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/miniconda3/envs/hicss-2024sdfs/lib/python3.10/site-packages/shapely/geometry/point.py:78\u001B[0m, in \u001B[0;36mPoint.__new__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m     76\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m np\u001B[38;5;241m.\u001B[39missubdtype(coords\u001B[38;5;241m.\u001B[39mdtype, np\u001B[38;5;241m.\u001B[39mnumber):\n\u001B[1;32m     77\u001B[0m     coords \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mfloat\u001B[39m(c) \u001B[38;5;28;01mfor\u001B[39;00m c \u001B[38;5;129;01min\u001B[39;00m coords]\n\u001B[0;32m---> 78\u001B[0m geom \u001B[38;5;241m=\u001B[39m \u001B[43mshapely\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpoints\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcoords\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     79\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(geom, Point):\n\u001B[1;32m     80\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid values passed to Point constructor\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/opt/miniconda3/envs/hicss-2024sdfs/lib/python3.10/site-packages/shapely/decorators.py:73\u001B[0m, in \u001B[0;36mmultithreading_enabled.<locals>.wrapped\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     62\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(func)\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     64\u001B[0m     array_args \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m     65\u001B[0m         arg \u001B[38;5;28;01mfor\u001B[39;00m arg \u001B[38;5;129;01min\u001B[39;00m args \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(arg, np\u001B[38;5;241m.\u001B[39mndarray) \u001B[38;5;129;01mand\u001B[39;00m arg\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mobject\u001B[39m\n\u001B[1;32m     66\u001B[0m     ] \u001B[38;5;241m+\u001B[39m [\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     71\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m arg\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mobject\u001B[39m\n\u001B[1;32m     72\u001B[0m     ]\n\u001B[0;32m---> 73\u001B[0m     old_flags \u001B[38;5;241m=\u001B[39m [arr\u001B[38;5;241m.\u001B[39mflags\u001B[38;5;241m.\u001B[39mwriteable \u001B[38;5;28;01mfor\u001B[39;00m arr \u001B[38;5;129;01min\u001B[39;00m array_args]\n\u001B[1;32m     74\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     75\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m arr \u001B[38;5;129;01min\u001B[39;00m array_args:\n",
      "File \u001B[0;32m~/opt/miniconda3/envs/hicss-2024sdfs/lib/python3.10/site-packages/shapely/decorators.py:73\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     62\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(func)\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     64\u001B[0m     array_args \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m     65\u001B[0m         arg \u001B[38;5;28;01mfor\u001B[39;00m arg \u001B[38;5;129;01min\u001B[39;00m args \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(arg, np\u001B[38;5;241m.\u001B[39mndarray) \u001B[38;5;129;01mand\u001B[39;00m arg\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mobject\u001B[39m\n\u001B[1;32m     66\u001B[0m     ] \u001B[38;5;241m+\u001B[39m [\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     71\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m arg\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mobject\u001B[39m\n\u001B[1;32m     72\u001B[0m     ]\n\u001B[0;32m---> 73\u001B[0m     old_flags \u001B[38;5;241m=\u001B[39m [arr\u001B[38;5;241m.\u001B[39mflags\u001B[38;5;241m.\u001B[39mwriteable \u001B[38;5;28;01mfor\u001B[39;00m arr \u001B[38;5;129;01min\u001B[39;00m array_args]\n\u001B[1;32m     74\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     75\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m arr \u001B[38;5;129;01min\u001B[39;00m array_args:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "episode_num = 0\n",
    "training_timesteps = 0\n",
    "\n",
    "while training_timesteps < total_timesteps:\n",
    "    restricted_environment.reset()\n",
    "    episode_reward = 0\n",
    "    episode_timesteps = 0\n",
    "    episode_num += 1\n",
    "    observation = None\n",
    "    action = None\n",
    "    last_td3_action = None\n",
    "\n",
    "    for agent in restricted_environment.agent_iter():\n",
    "        next_observation, reward, termination, truncation, info = restricted_environment.last()\n",
    "\n",
    "        # Turn of the agent\n",
    "        if agent == 'agent_0':\n",
    "            episode_reward += reward\n",
    "            episode_timesteps += 1\n",
    "\n",
    "            flattened_next_observation = flatten(restricted_environment.observation_space('agent_0'),\n",
    "                                                 next_observation, max_len=8, raise_error=False)\n",
    "\n",
    "            if episode_timesteps > 1:\n",
    "                replay_buffer.add(observation,\n",
    "                                  last_td3_action,\n",
    "                                  flattened_next_observation,\n",
    "                                  reward,\n",
    "                                  termination or truncation)\n",
    "            observation = flattened_next_observation\n",
    "\n",
    "            training_timesteps += 1\n",
    "            if training_timesteps < td3_config['train_after_timesteps']:\n",
    "                    action = np.random.uniform(-110.0, 110.0, (1,))\n",
    "            else:\n",
    "                det_action = td3.select_action(observation)\n",
    "                noise = np.random.normal(0, td3_config['max_action'] * td3_config['exploration_noise'], size=td3_config['action_dim'])\n",
    "                action = (det_action + noise).clip(-td3_config['max_action'], td3_config['max_action'])\n",
    "            if training_timesteps >= td3_config['train_after_timesteps']:\n",
    "                td3.train(replay_buffer, td3_config['batch_size'])\n",
    "            last_td3_action = action\n",
    "        # Or restrictor\n",
    "        else:\n",
    "            action = restrictor.act(next_observation)\n",
    "\n",
    "        # None action if episode is done\n",
    "        if termination or truncation:\n",
    "            action = None\n",
    "\n",
    "        restricted_environment.step(action)\n",
    "\n",
    "        if training_timesteps % 50 == 0:\n",
    "            print(evaluate(td3, restrictor))\n",
    "\n",
    "    print(f'Finished episode {episode_num} with reward {episode_reward}')\n",
    "\n",
    "restricted_environment.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
